<!DOCTYPE html>
<html>
<head>
    <title>Learning Report - Al Karama Urban Climate Analysis</title>
    <meta charset="utf-8">
    <style>
        * { box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #fafafa;
            color: #333;
        }
        h1 { color: #1565c0; border-bottom: 3px solid #1565c0; padding-bottom: 10px; }
        h2 { color: #1565c0; margin-top: 40px; border-left: 4px solid #1565c0; padding-left: 15px; }
        h3 { color: #333; margin-top: 25px; }
        .toc { background: #e3f2fd; padding: 20px; border-radius: 8px; margin: 20px 0; }
        .toc a { color: #1565c0; text-decoration: none; }
        .toc a:hover { text-decoration: underline; }
        .toc ul { margin: 10px 0; }
        .section { background: white; padding: 25px; border-radius: 8px; margin: 20px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .highlight { background: #fff3e0; padding: 15px; border-radius: 6px; border-left: 4px solid #ff9800; margin: 15px 0; }
        .code { background: #263238; color: #aed581; padding: 15px; border-radius: 6px; font-family: monospace; overflow-x: auto; margin: 15px 0; }
        table { width: 100%; border-collapse: collapse; margin: 15px 0; }
        th, td { padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }
        th { background: #f5f5f5; }
        .metric { display: inline-block; background: #e8f5e9; padding: 5px 10px; border-radius: 4px; margin: 3px; }
        .finding { background: #e8f5e9; padding: 15px; border-radius: 6px; border-left: 4px solid #4caf50; margin: 15px 0; }
        .limitation { background: #ffebee; padding: 15px; border-radius: 6px; border-left: 4px solid #f44336; margin: 15px 0; }
        .diagram { background: #f5f5f5; padding: 20px; border-radius: 8px; text-align: center; margin: 20px 0; font-family: monospace; }
        img { max-width: 100%; }
        .formula { background: #f5f5f5; padding: 10px 20px; border-radius: 6px; font-family: monospace; margin: 10px 0; }
    </style>
</head>
<body>

<h1>Learning Report: Al Karama Urban Climate Analysis</h1>
<p><strong>Location:</strong> Al Karama, Dubai, UAE<br>
<strong>Purpose:</strong> Understand urban heat, vegetation, and pedestrian comfort using freely available data<br>
<strong>Date:</strong> January 2026</p>

<div class="toc">
    <strong>Table of Contents</strong>
    <ul>
        <li><a href="#overview">1. Project Overview</a></li>
        <li><a href="#data">2. Data Sources</a></li>
        <li><a href="#streetview">3. Street View Analysis (GVI, SVF)</a></li>
        <li><a href="#satellite">4. Satellite Analysis (LST, NDVI, NDBI)</a></li>
        <li><a href="#building-heights">5. Building Height Enhancement (GEE)</a></li>
        <li><a href="#combined">6. Combined Analysis</a></li>
        <li><a href="#network">7. Network Analysis</a></li>
        <li><a href="#clusters">8. Cluster Analysis</a></li>
        <li><a href="#shade">9. Building Shade Analysis</a>
            <ul><li><a href="#shade-poi">9.8 Points of Interest (Overpass API)</a></li></ul>
        </li>
        <li><a href="#findings">10. Key Findings</a></li>
        <li><a href="#limitations">11. Limitations</a></li>
        <li><a href="#files">12. Output Files Reference</a></li>
        <li><a href="#field-survey">13. Field Survey Guide</a></li>
        <li><a href="#unused-depth">Appendix A: Unused Methodology &mdash; Depth Estimation</a></li>
    </ul>
</div>

<!-- ============================================================ -->
<h2 id="overview">1. Project Overview</h2>
<div class="section">
    <h3>What We Did</h3>
    <p>We analyzed the urban climate and pedestrian comfort of Al Karama district using two complementary data sources:</p>
    <ol>
        <li><strong>Street View Images</strong> (Mapillary) - Ground-level perspective of what pedestrians see</li>
        <li><strong>Satellite Imagery</strong> (Landsat, Sentinel-2) - Bird's eye view of temperature and vegetation</li>
    </ol>

    <div class="diagram">
        <pre>
┌─────────────────────────────────────────────────────────────┐
│                    DATA SOURCES                              │
├─────────────────────────┬───────────────────────────────────┤
│   STREET VIEW           │         SATELLITE                 │
│   (Mapillary)           │    (Landsat + Sentinel-2)         │
│                         │                                   │
│   • 11,651 images       │    • 90,300 grid cells            │
│   • Ground-level view   │    • 10m resolution               │
│   • What pedestrians    │    • Temperature (LST)            │
│     actually see        │    • Vegetation (NDVI)            │
└────────────┬────────────┴─────────────────┬─────────────────┘
             │                              │
             ▼                              ▼
┌─────────────────────────┐    ┌─────────────────────────────┐
│  Green View Index (GVI) │    │  Land Surface Temp (LST)    │
│  Sky View Factor (SVF)  │    │  Vegetation Index (NDVI)    │
│                         │    │  Built-up Index (NDBI)      │
└────────────┬────────────┘    └─────────────────┬───────────┘
             │                                   │
             └─────────────┬─────────────────────┘
                           ▼
              ┌─────────────────────────┐
              │   COMBINED ANALYSIS     │
              │  • Heat Mitigation      │
              │  • Pedestrian Comfort   │
              │  • Network Centrality   │
              │  • Climate Clusters     │
              └─────────────────────────┘
        </pre>
    </div>

    <h3>Why This Matters</h3>
    <p>Urban heat is a major issue in Dubai. By identifying where heat stress is worst and where interventions would help the most people, planners can make better decisions about:</p>
    <ul>
        <li>Where to plant trees</li>
        <li>Where to add shade structures</li>
        <li>Which streets to prioritize for pedestrian improvements</li>
    </ul>
</div>

<!-- ============================================================ -->
<h2 id="data">2. Data Sources</h2>
<div class="section">
    <h3>2.1 Mapillary Street View Images</h3>
    <table>
        <tr><th>Property</th><th>Value</th></tr>
        <tr><td>Source</td><td>Mapillary (crowdsourced street imagery)</td></tr>
        <tr><td>Images downloaded</td><td>11,651</td></tr>
        <tr><td>Coverage</td><td>Al Karama district boundary</td></tr>
        <tr><td>Cost</td><td>Free (API access)</td></tr>
        <tr><td>Tool used</td><td>ZenSVI Python library</td></tr>
    </table>

    <div class="code">
# How we downloaded images
from zensvi.download import MLYDownloader

mly = MLYDownloader(log_path="logs")
mly.download_svi(
    dir_output="data/mapillary_svi",
    input_shp="data/al_karama.geojson",
    lat=None, lon=None,
    id_columns=None
)
    </div>

    <h3>2.2 Satellite Imagery</h3>
    <table>
        <tr><th>Satellite</th><th>Data</th><th>Resolution</th><th>Use</th></tr>
        <tr><td>Landsat 8/9</td><td>Thermal infrared</td><td>30m (100m native)</td><td>Land Surface Temperature</td></tr>
        <tr><td>Sentinel-2</td><td>Multispectral</td><td>10m</td><td>NDVI, NDBI vegetation/built-up</td></tr>
    </table>

    <div class="highlight">
        <strong>Google Earth Engine (GEE):</strong> We used GEE to access and process satellite data. It's free for research/academic use. You need to register at <a href="https://earthengine.google.com/">earthengine.google.com</a>.
    </div>

    <h3>2.3 OpenStreetMap</h3>
    <table>
        <tr><th>Data</th><th>Count</th><th>Use</th></tr>
        <tr><td>Buildings</td><td>3,243</td><td>3D visualization, height data</td></tr>
        <tr><td>Street network</td><td>5,975 edges</td><td>Centrality analysis</td></tr>
        <tr><td>Points of Interest</td><td>1,290</td><td>Amenity overlay on 3D shade map</td></tr>
    </table>

    <h3>2.4 Overpass API (Points of Interest)</h3>
    <table>
        <tr><th>Property</th><th>Value</th></tr>
        <tr><td>Source</td><td><a href="https://overpass-api.de/">Overpass API</a> (OpenStreetMap query interface)</td></tr>
        <tr><td>Query area</td><td>Al Karama bounding box (25.238&ndash;25.259&deg;N, 55.292&ndash;55.313&deg;E)</td></tr>
        <tr><td>OSM tags queried</td><td><code>amenity</code>, <code>shop</code>, <code>tourism</code>, <code>office</code>, <code>leisure</code>, <code>healthcare</code></td></tr>
        <tr><td>Raw elements returned</td><td>1,419</td></tr>
        <tr><td>After noise filtering</td><td>1,290</td></tr>
        <tr><td>Categories</td><td>8 (Food, Shopping, Hotel, Health, Religious, Services, Leisure, Education)</td></tr>
        <tr><td>Cost</td><td>Free (public API, rate-limited)</td></tr>
        <tr><td>Caching</td><td><code>pois_cache.json</code> &mdash; avoids repeat API calls on re-run</td></tr>
    </table>

    <div class="highlight">
        <strong>Noise filtering:</strong> 18 OSM types are excluded as "urban furniture" that would clutter the map: bench, waste_basket, parking, shelter, bollard, fire_hydrant, street_lamp, etc. This reduces the raw 1,419 elements to 1,290 meaningful PoIs.
    </div>
</div>

<!-- ============================================================ -->
<h2 id="streetview">3. Street View Analysis</h2>
<div class="section">
    <h3>3.1 Green View Index (GVI)</h3>
    <p><strong>What it measures:</strong> The percentage of green pixels (vegetation) visible in a street view image.</p>

    <div class="formula">
        GVI = (Green pixels in image) / (Total pixels in image) × 100%
    </div>

    <p><strong>How it's calculated:</strong></p>
    <ol>
        <li>Take a street view image</li>
        <li>Convert to a color space that separates green vegetation</li>
        <li>Use a vegetation index formula to identify green pixels</li>
        <li>Count the percentage of green pixels</li>
    </ol>

    <div class="finding">
        <strong>Al Karama Result:</strong> Mean GVI = 3.55%<br>
        This is very low - most streets have minimal visible vegetation.
    </div>

    <h3>3.2 Sky View Factor (SVF)</h3>
    <p><strong>What it measures:</strong> The percentage of sky visible from a point on the street. Lower SVF = more shading from buildings/trees.</p>

    <div class="formula">
        SVF = (Sky pixels in image) / (Total pixels in upper hemisphere) × 100%
    </div>

    <p><strong>Interpretation:</strong></p>
    <ul>
        <li>SVF = 100%: Open area, no obstructions (full sun exposure)</li>
        <li>SVF = 50%: Half the sky blocked (moderate shading)</li>
        <li>SVF = 20%: Narrow street canyon (good shading)</li>
    </ul>

    <div class="finding">
        <strong>Al Karama Result:</strong> Mean SVF = 31.4%<br>
        Moderate sky exposure - some shading from buildings but not dense urban canyon.
    </div>

    <p><em>Note: Monocular depth estimation was explored but not adopted in the final analysis. See <a href="#unused-depth">Appendix A: Unused Methodology &mdash; Depth Estimation</a> for details.</em></p>
</div>

<!-- ============================================================ -->
<h2 id="satellite">4. Satellite Analysis</h2>
<div class="section">
    <h3>4.1 Land Surface Temperature (LST)</h3>
    <p><strong>What it measures:</strong> The temperature of the ground/surface as seen from space.</p>

    <div class="highlight">
        <strong>Important:</strong> LST is NOT air temperature. It measures how hot surfaces (roads, buildings, sand) are. LST is typically higher than air temperature during the day.
    </div>

    <p><strong>How it's calculated from Landsat:</strong></p>
    <div class="formula">
LST = Brightness Temperature / (1 + (λ × BT / ρ) × ln(ε))

Where:
  λ = wavelength of thermal band (10.8 μm)
  BT = brightness temperature from satellite
  ρ = h × c / σ (Planck's constant × speed of light / Boltzmann)
  ε = surface emissivity (assumed 0.95 for urban areas)
    </div>

    <div class="finding">
        <strong>Al Karama Result:</strong><br>
        Mean LST = 48.6°C (summer)<br>
        Range: 36°C to 54°C<br>
        The 18°C variation shows some areas are significantly cooler (likely parks/vegetation).
    </div>

    <h3>4.2 NDVI (Normalized Difference Vegetation Index)</h3>
    <p><strong>What it measures:</strong> Vegetation health/density from satellite perspective.</p>

    <div class="formula">
NDVI = (NIR - Red) / (NIR + Red)

Where:
  NIR = Near-infrared reflectance (Sentinel-2 Band 8)
  Red = Red reflectance (Sentinel-2 Band 4)
    </div>

    <p><strong>Interpretation:</strong></p>
    <table>
        <tr><th>NDVI Value</th><th>Meaning</th></tr>
        <tr><td>-1.0 to 0</td><td>Water, bare soil, buildings</td></tr>
        <tr><td>0 to 0.2</td><td>Sparse vegetation, dry grass</td></tr>
        <tr><td>0.2 to 0.4</td><td>Moderate vegetation</td></tr>
        <tr><td>0.4 to 0.6</td><td>Dense vegetation</td></tr>
        <tr><td>0.6 to 1.0</td><td>Very dense, healthy vegetation</td></tr>
    </table>

    <div class="finding">
        <strong>Al Karama Result:</strong> Mean NDVI = 0.104<br>
        Very low - mostly built-up with sparse vegetation. Only 11% of area has NDVI > 0.3.
    </div>

    <h3>4.3 NDBI (Normalized Difference Built-up Index)</h3>
    <p><strong>What it measures:</strong> Built-up/urban density.</p>

    <div class="formula">
NDBI = (SWIR - NIR) / (SWIR + NIR)

Where:
  SWIR = Short-wave infrared (Sentinel-2 Band 11)
  NIR = Near-infrared (Sentinel-2 Band 8)
    </div>

    <p>High NDBI = more buildings/concrete. Low NDBI = vegetation or water.</p>

    <h3>4.4 Thermal Sharpening (30m → 10m)</h3>
    <p><strong>What it does:</strong> Downscales coarse Landsat thermal data (30m) to match Sentinel-2 resolution (10m) using the correlation between temperature and vegetation.</p>

    <p><strong>Why it's needed:</strong> Landsat thermal bands have 100m native resolution (resampled to 30m). For detailed urban analysis, we want finer resolution to see temperature variations at street level.</p>

    <div class="formula">
Method: Linear regression of LST vs NDVI at 30m → Apply model to 10m NDVI

1. Sample both LST (30m) and NDVI (10m aggregated to 30m) at random points
2. Fit regression: LST = a + b × NDVI
3. Apply to 10m NDVI: LST_10m = a + b × NDVI_10m
4. Add residuals from nearest 30m pixel for local calibration
    </div>

    <div class="highlight">
        <strong>Al Karama Result:</strong><br>
        Regression: LST = 49.02 + (-3.66 × NDVI)<br>
        R² = 0.045 (weak correlation)<br>
        RMSE = 0.32°C (difference between 30m and 10m)<br><br>
        <em>Note: Weak R² is expected in urban areas where impervious surfaces dominate. The method works better in areas with more vegetation variation.</em>
    </div>
</div>

<!-- ============================================================ -->
<h2 id="building-heights">5. Building Height Enhancement (GEE)</h2>
<div class="section">
    <h3>5.1 The Problem</h3>
    <p>OpenStreetMap provides building footprints for Al Karama (3,243 buildings), but only <strong>78 buildings (2.4%)</strong> have real height data. The remaining 3,165 buildings default to 9m (assumed 3 floors), which produces an unrealistic 3D model where most buildings appear the same height.</p>

    <div class="highlight">
        <strong>Goal:</strong> Use freely available global datasets from Google Earth Engine to estimate building heights for the 97.6% of buildings missing real data.
    </div>

    <h3>5.2 Datasets Evaluated</h3>
    <p>We tested multiple GEE datasets for coverage over Dubai/Al Karama:</p>

    <table>
        <tr><th>Dataset</th><th>Resolution</th><th>Coverage</th><th>What it provides</th></tr>
        <tr><td>Open Buildings 2.5D Temporal</td><td>~2.5m</td><td>Not available (0 images)</td><td>Would have had individual building heights</td></tr>
        <tr><td><strong>GHSL Built-C</strong></td><td><strong>10m</strong></td><td><strong>84,182 pixels</strong></td><td>Height classes (categorical)</td></tr>
        <tr><td><strong>GHSL Built-H</strong></td><td><strong>100m</strong></td><td><strong>883 pixels</strong></td><td>Continuous heights (meters)</td></tr>
        <tr><td><strong>nDSM (ALOS-SRTM)</strong></td><td><strong>30m</strong></td><td><strong>10,416 pixels</strong></td><td>Surface model difference</td></tr>
    </table>

    <h3>5.3 GHSL Built-C (10m) - Height Classes</h3>
    <p><strong>Source:</strong> JRC Global Human Settlement Layer (GHSL), 2018 epoch</p>
    <p><strong>Collection:</strong> <code>JRC/GHSL/P2023A/GHS_BUILT_C/2018</code></p>

    <p>This dataset classifies built-up areas into height bands at 10m resolution. Each pixel encodes both building type (residential, non-residential, mixed) and height class:</p>

    <table>
        <tr><th>Height Class</th><th>Range</th><th>Midpoint Used</th></tr>
        <tr><td>1</td><td>&le;3m</td><td>3.0m</td></tr>
        <tr><td>2</td><td>3-6m</td><td>4.5m</td></tr>
        <tr><td>3</td><td>6-15m</td><td>10.5m</td></tr>
        <tr><td>4</td><td>15-30m</td><td>22.5m</td></tr>
        <tr><td>5</td><td>&gt;30m</td><td>45.0m</td></tr>
    </table>

    <p><strong>Method:</strong> For each OSM building polygon, we used <code>reduceRegions</code> with a <code>mode</code> reducer to extract the dominant height class within the footprint, then converted to the midpoint height.</p>

    <div class="code">
# Extract height class per building polygon
image = ee.Image("JRC/GHSL/P2023A/GHS_BUILT_C/2018")
band = image.select('built_characteristics')

reduced = band.reduceRegions(
    collection=building_polygons,
    reducer=ee.Reducer.mode(),
    scale=10,
)

# Convert class to height: height_band = class_value % 10
# Then map to midpoint heights
    </div>

    <h3>5.4 GHSL Built-H (100m) - Continuous Heights</h3>
    <p><strong>Collection:</strong> <code>JRC/GHSL/P2023A/GHS_BUILT_H/2018</code></p>
    <p>Provides continuous building height estimates in meters at 100m resolution. Less spatial detail but gives actual meter values rather than classes.</p>
    <p><strong>Method:</strong> <code>reduceRegions</code> with <code>mean</code> reducer per building polygon.</p>

    <div class="highlight">
        <strong>Limitation:</strong> GHSL Built-H caps at ~40m for this area (mean 13.5m). Al Karama has buildings taller than 40m, so GHSL may underestimate the tallest buildings. OSM real heights (up to 230m) are preserved where available.
    </div>

    <h3>5.5 nDSM: Normalized Digital Surface Model (30m)</h3>
    <p><strong>What it is:</strong> The difference between a Digital Surface Model (DSM, which includes buildings/trees) and a Digital Elevation Model (DEM, bare ground only).</p>

    <div class="formula">
nDSM = DSM - DEM

Where:
  DSM = ALOS AW3D30 (JAXA, 2006-2011, 30m resolution)
  DEM = SRTM (NASA, 2000, 30m resolution)
    </div>

    <p>Positive nDSM values indicate above-ground structures (buildings, trees). However, this approach is noisy because the two datasets were acquired years apart (2000 vs 2006-2011), and both have their own measurement uncertainties.</p>

    <div class="limitation">
        <strong>Limitation:</strong> The temporal mismatch between SRTM (2000) and ALOS (2006-2011) means buildings constructed between these dates will appear in the nDSM, but pre-existing terrain changes or demolitions can produce artifacts. We applied a threshold of &gt;2m to filter out noise.
    </div>

    <h3>5.6 Priority Merge System</h3>
    <p>We merged heights from all sources using a priority system that preserves the most reliable data:</p>

    <table>
        <tr><th>Priority</th><th>Source</th><th>Resolution</th><th>Rationale</th></tr>
        <tr><td>1 (highest)</td><td>OSM real height (&ne;9m)</td><td>Individual</td><td>Surveyed or mapped by contributors</td></tr>
        <tr><td>2</td><td>GHSL Built-C</td><td>10m</td><td>Best spatial resolution, height classes</td></tr>
        <tr><td>3</td><td>GHSL Built-H</td><td>100m</td><td>Continuous values but coarser</td></tr>
        <tr><td>4</td><td>nDSM</td><td>30m</td><td>Noisy but independent measurement</td></tr>
        <tr><td>5 (lowest)</td><td>Default</td><td>n/a</td><td>Keep 9m assumption</td></tr>
    </table>

    <h3>5.7 Results</h3>
    <div class="finding">
        <strong>Coverage improved from 2.4% to 99.5%:</strong>
        <table>
            <tr><th>Source</th><th>Buildings</th><th>Percentage</th></tr>
            <tr><td>OSM real height</td><td>78</td><td>2.4%</td></tr>
            <tr><td>GHSL Built-C (10m)</td><td>3,055</td><td>94.2%</td></tr>
            <tr><td>GHSL Built-H (100m)</td><td>80</td><td>2.5%</td></tr>
            <tr><td>nDSM (30m)</td><td>14</td><td>0.4%</td></tr>
            <tr><td>Default (9m)</td><td>16</td><td>0.5%</td></tr>
            <tr><td><strong>Total with data</strong></td><td><strong>3,227</strong></td><td><strong>99.5%</strong></td></tr>
        </table>
    </div>

    <p>GHSL Built-C dominated because its 10m resolution matches well with building footprint sizes, and it had near-complete coverage of the study area. The 3D visualization now includes a "Color by Source" toggle to show which dataset provided each building's height.</p>

    <div class="highlight">
        <strong>Height distribution by source:</strong><br>
        OSM real: 6-230m (median 36m) - includes known tall buildings<br>
        GHSL Built-C: 3-45m (median 10.5m) - 5 height classes<br>
        GHSL Built-H: 2.5-33.7m (median 10.3m) - continuous<br>
        nDSM: 2.7-10.8m (median 4.0m) - low-rise buildings only
    </div>
</div>

<!-- ============================================================ -->
<h2 id="combined">6. Combined Analysis</h2>
<div class="section">
    <h3>6.1 Heat Mitigation Priority</h3>
    <p><strong>Goal:</strong> Identify locations where interventions (tree planting, shade) would have the most impact.</p>

    <p><strong>Method:</strong> Combine multiple factors into a priority score:</p>

    <div class="formula">
Priority Score = 0.40 × LST_normalized
              + 0.25 × (1 - GVI_normalized)  [low greenery = high priority]
              + 0.20 × (1 - NDVI_normalized) [low vegetation = high priority]
              + 0.15 × SVF_normalized        [high exposure = high priority]
    </div>

    <div class="finding">
        <strong>Result:</strong><br>
        Critical priority: 2,892 locations (25%)<br>
        High priority: 6,122 locations (53%)<br>
        <br>
        78% of Al Karama needs heat mitigation interventions.
    </div>

    <h3>6.2 Pedestrian Comfort Index (PCI)</h3>
    <p><strong>Goal:</strong> Rate streets by walking comfort.</p>

    <div class="formula">
PCI = 0.40 × Temperature_comfort (inverse of LST)
    + 0.35 × Shade (1 - SVF)
    + 0.25 × Vegetation_comfort (GVI)
    </div>

    <p><strong>Interpretation:</strong></p>
    <table>
        <tr><th>PCI</th><th>Comfort Level</th></tr>
        <tr><td>> 0.6</td><td>Very Comfortable</td></tr>
        <tr><td>0.45 - 0.6</td><td>Comfortable</td></tr>
        <tr><td>0.3 - 0.45</td><td>Moderate</td></tr>
        <tr><td>< 0.3</td><td>Uncomfortable</td></tr>
    </table>

    <div class="finding">
        <strong>Result:</strong> Only 29% of streets are comfortable for pedestrians.
    </div>
</div>

<!-- ============================================================ -->
<h2 id="network">7. Network Analysis</h2>
<div class="section">
    <h3>7.1 What is Network Centrality?</h3>
    <p>Network analysis treats streets as a graph (nodes = intersections, edges = street segments) to understand which streets are most important for movement.</p>

    <h3>7.2 Betweenness Centrality</h3>
    <p><strong>What it measures:</strong> How often a street lies on the shortest path between other locations.</p>

    <div class="formula">
Betweenness(v) = Σ (σst(v) / σst)

Where:
  σst = total number of shortest paths from node s to node t
  σst(v) = number of those paths that pass through v
    </div>

    <p><strong>Interpretation:</strong> High betweenness = many people pass through this street to get from A to B. These are main corridors.</p>

    <h3>7.3 Closeness Centrality</h3>
    <p><strong>What it measures:</strong> How close (accessible) a location is to all other locations.</p>

    <div class="formula">
Closeness(v) = (n-1) / Σ d(v,u)

Where:
  n = number of nodes
  d(v,u) = shortest path distance from v to u
    </div>

    <p><strong>Interpretation:</strong> High closeness = easy to reach from anywhere. Central, accessible locations.</p>

    <h3>7.4 Intervention Priority</h3>
    <p>We combined centrality with comfort to find streets where improvements help the most people:</p>

    <div class="formula">
Intervention Priority = Centrality × (1 - Comfort)

High priority = busy street that is uncomfortable
    </div>

    <div class="finding">
        <strong>Result:</strong> 51 streets identified as high priority - heavily used but uncomfortable.
    </div>

    <h3>7.5 Edge Effects</h3>
    <div class="highlight">
        <strong>Important caveat:</strong> Centrality calculations are affected by study area boundaries. Streets at the edge appear less important because paths can't continue beyond our boundary. We addressed this by expanding the analysis area (+500m buffer) and then clipping results back to Al Karama.
    </div>
</div>

<!-- ============================================================ -->
<h2 id="clusters">8. Cluster Analysis</h2>
<div class="section">
    <h3>8.1 K-Means Clustering</h3>
    <p><strong>Goal:</strong> Group locations into distinct "urban climate zones" based on their characteristics.</p>

    <p><strong>Method:</strong></p>
    <ol>
        <li>Select features: GVI, SVF, LST, NDVI</li>
        <li>Standardize features (z-scores) so they're comparable</li>
        <li>Run K-means algorithm with k=4 clusters</li>
        <li>Label clusters based on their characteristics</li>
    </ol>

    <div class="finding">
        <strong>Result - 4 Urban Climate Zones:</strong>
        <table>
            <tr><th>Zone</th><th>Count</th><th>GVI</th><th>SVF</th><th>LST</th><th>Character</th></tr>
            <tr><td>Hot & Exposed</td><td>3,962</td><td>2.5%</td><td>46%</td><td>50.6°C</td><td>Open areas, full sun</td></tr>
            <tr><td>Hot & Shaded</td><td>3,386</td><td>1.6%</td><td>19%</td><td>50.2°C</td><td>Buildings block sun but no trees</td></tr>
            <tr><td>Green & Shaded</td><td>1,083</td><td>15.3%</td><td>30%</td><td>50.1°C</td><td>Best areas - has vegetation</td></tr>
            <tr><td>Mixed/Cool</td><td>1,667</td><td>2.4%</td><td>32%</td><td>48.5°C</td><td>Cooler but reason unclear</td></tr>
        </table>
    </div>

    <h3>8.2 Green Space Accessibility</h3>
    <p><strong>Method:</strong> For each street view point, calculate distance to nearest "green space" (cells with NDVI > 0.3).</p>

    <div class="finding">
        <strong>Result:</strong><br>
        Mean distance to green: 90m<br>
        95.7% of streets within 200m of green space<br>
        <br>
        <em>Note: "Green space" here means satellite-detected vegetation, not necessarily public parks.</em>
    </div>
</div>

<!-- ============================================================ -->
<h2 id="shade">9. Building &amp; Tree Canopy Shade Analysis</h2>
<div class="section">
    <h3>9.1 Objective</h3>
    <p>Quantify how much shade buildings <strong>and tree canopies</strong> cast on streets during peak summer, and identify which streets are most exposed to direct sun. This extends the building height data (Section 5) and integrates tree canopy data from the Meta 1m Global Canopy Height Map.</p>

    <h3>9.2 Solar Position (NOAA Algorithm)</h3>
    <p><strong>Method:</strong> Implemented the NOAA solar position spreadsheet algorithm using pure numpy/math (no external solar libraries). The algorithm computes solar altitude and azimuth from Julian Day, solar declination, hour angle, and observer coordinates.</p>

    <div class="formula">
        Julian Day &rarr; Solar Declination &rarr; Hour Angle &rarr; Altitude &amp; Azimuth
    </div>

    <p><strong>Analysis date:</strong> July 15 (peak summer in Dubai), 7 time slots from 6 AM to 6 PM.</p>

    <table>
        <tr><th>Local Time</th><th>Altitude</th><th>Azimuth</th><th>Shadow Length Factor</th></tr>
        <tr><td>06:00</td><td>3.7&deg;</td><td>68.0&deg; (ENE)</td><td>15.32&times; height</td></tr>
        <tr><td>08:00</td><td>29.7&deg;</td><td>78.7&deg; (E)</td><td>1.75&times;</td></tr>
        <tr><td>10:00</td><td>56.6&deg;</td><td>88.9&deg; (E)</td><td>0.66&times;</td></tr>
        <tr><td>12:00</td><td>83.1&deg;</td><td>122.6&deg; (SE)</td><td>0.12&times; (near overhead)</td></tr>
        <tr><td>14:00</td><td>67.9&deg;</td><td>264.9&deg; (W)</td><td>0.41&times;</td></tr>
        <tr><td>16:00</td><td>40.8&deg;</td><td>277.2&deg; (W)</td><td>1.16&times;</td></tr>
        <tr><td>18:00</td><td>14.3&deg;</td><td>287.2&deg; (WNW)</td><td>3.93&times;</td></tr>
    </table>

    <div class="highlight">
        <strong>Key insight:</strong> At noon in July, the sun is nearly overhead (83&deg; altitude) so shadows are minimal. Early morning (6 AM) and late afternoon (6 PM) produce extremely long shadows &mdash; at 6 AM the sun is only 3.7&deg; above the horizon, casting shadows over 15&times; building height. This reveals how shadow coverage changes dramatically throughout the day.
    </div>

    <h3>9.3 Shadow Projection Method</h3>
    <p><strong>For each building and tree canopy polygon at each time:</strong></p>
    <ol>
        <li>Calculate shadow length: <code>shadow_length = height / tan(altitude)</code></li>
        <li>Determine shadow direction: opposite to sun azimuth</li>
        <li>Create shadow polygon: convex hull of footprint + translated tip footprint</li>
        <li>All calculations in UTM Zone 40N (EPSG:32640) for metric accuracy</li>
    </ol>

    <div class="formula">
        shadow_length = height / tan(solar_altitude)<br>
        shadow_direction = sun_azimuth + 180&deg;
    </div>

    <p>Shadow sources include <strong>3,243 buildings</strong> and <strong>1,033 tree canopy polygons</strong>, producing ~30,000 individual shadow projections across 7 time slots.</p>

    <h3>9.4 Tree Canopy Integration</h3>
    <p><strong>Data source:</strong> Meta 1m Global Canopy Height Map, accessed via Google Earth Engine. The canopy data was processed in three stages:</p>
    <ol>
        <li><strong>Canopy polygon extraction:</strong> The raster canopy height image was thresholded (&gt;2m) and converted to 1,033 vector polygons representing tree canopy areas.</li>
        <li><strong>Height sampling:</strong> 183 sample points with canopy height values were extracted from the raster.</li>
        <li><strong>IDW height interpolation:</strong> Each polygon centroid was assigned a height using Inverse Distance Weighting (IDW) interpolation from the 3 nearest sample points (within 500m). Polygons with no nearby samples received the median height (3.0m).</li>
    </ol>

    <div class="formula">
        height_polygon = &Sigma;(w<sub>i</sub> &times; h<sub>i</sub>) / &Sigma;(w<sub>i</sub>), &nbsp; where w<sub>i</sub> = 1 / d<sub>i</sub>&sup2;
    </div>

    <table>
        <tr><th>Canopy Metric</th><th>Value</th></tr>
        <tr><td>Total canopy polygons</td><td>1,033</td></tr>
        <tr><td>Height range</td><td>1.0 &ndash; 11.9 m</td></tr>
        <tr><td>Mean height</td><td>3.2 m</td></tr>
        <tr><td>Median height</td><td>2.7 m</td></tr>
        <tr><td>Sample points used for IDW</td><td>183</td></tr>
    </table>

    <h3>9.5 Street Shade Calculation</h3>
    <p><strong>Method:</strong> For each time slot, union all building <em>and</em> tree canopy shadows using a chunked spatial approach (200m grid tiles), then calculate the fraction of each street segment that falls within shadow.</p>

    <div class="formula">
        shade_fraction = shaded_length / total_length
    </div>

    <p>Daily average shade is computed across all 7 time slots. Performance is managed via spatial indexing (STRtree) and chunked union operations.</p>

    <h3>9.6 Results</h3>

    <table>
        <tr><th>Time</th><th>Avg Shade</th><th>Well-shaded (&ge;50%)</th><th>Exposed (&lt;20%)</th></tr>
        <tr><td>06:00 AM</td><td><strong>93.8%</strong></td><td>5,339 / 5,656</td><td>155</td></tr>
        <tr><td>08:00 AM</td><td>39.4%</td><td>2,250 / 5,656</td><td>1,842</td></tr>
        <tr><td>10:00 AM</td><td>19.9%</td><td>1,106 / 5,656</td><td>3,249</td></tr>
        <tr><td>12:00 PM</td><td>5.9%</td><td>288 / 5,656</td><td>5,052</td></tr>
        <tr><td>02:00 PM</td><td>13.2%</td><td>722 / 5,656</td><td>3,907</td></tr>
        <tr><td>04:00 PM</td><td>26.6%</td><td>1,511 / 5,656</td><td>2,570</td></tr>
        <tr><td>06:00 PM</td><td><strong>51.6%</strong></td><td>3,015 / 5,656</td><td>1,309</td></tr>
    </table>

    <div class="finding">
        <strong>Daily summary (buildings + trees combined):</strong><br>
        &bull; Average shade coverage across 7 time slots: <strong>35.8%</strong><br>
        &bull; Well-shaded streets (&ge;50% daily average): <strong>1,208 / 5,656</strong> (21%)<br>
        &bull; Exposed streets (&lt;20% daily average): <strong>1,639 / 5,656</strong> (29%)<br>
        &bull; Most shade at 6 AM (93.8%) and 6 PM (51.6%) &mdash; long shadows from low sun angle<br>
        &bull; Least shade at noon (5.9%) &mdash; sun nearly overhead at 83&deg;
    </div>

    <div class="finding">
        <strong>Key outputs:</strong><br>
        &bull; Shadow polygons for each of the 7 time slots (GeoJSON) &mdash; separate building and tree shadow layers<br>
        &bull; Shade percentage per street per hour (CSV, 5,656 streets &times; 7 hours)<br>
        &bull; Interactive 2D map with time slider, building shadow toggle, and tree shadow toggle<br>
        &bull; Interactive 3D map with extruded buildings (gray) and tree canopy (green), projected shadow overlays, and GPU-rendered sun shadows<br>
        &bull; Streets colored by shade coverage (red=exposed, green=shaded)
    </div>

    <h3>9.7 Visualisation</h3>
    <p>Two interactive HTML maps are provided:</p>
    <ul>
        <li><strong>2D shade map</strong> (<a href="shade_analysis/shade_map.html">shade_map.html</a>): Leaflet map with a time slider (6 AM &ndash; 6 PM). Three toggle layers: building shadows (dark gray), tree shadows (green), and street shade percentages (color-coded). Shadow polygons update as you scrub the slider.</li>
        <li><strong>3D shade map</strong> (<a href="shade_analysis/shade_map_3d.html">shade_map_3d.html</a>): deck.gl map with extruded buildings, green tree canopy polygons, and 1,290 Overpass API Points of Interest shown as emoji icons (&#127828;&#128717;&#65039;&#127976; etc.) with category filter pills. Features both pre-computed projected shadow overlays (building + tree, toggleable) and GPU-rendered sun shadows via deck.gl <code>_SunLight</code>. Tooltips show building height, tree height, PoI name/category, and per-street shade percentage.</li>
    </ul>

    <h3 id="shade-poi">9.8 Points of Interest (Overpass API)</h3>
    <p><strong>Objective:</strong> Overlay a rich, categorized layer of Points of Interest on the 3D shade map so users can see which amenities (restaurants, shops, clinics, schools, etc.) exist in relation to shade coverage.</p>

    <h4>Data Source</h4>
    <p>PoIs are fetched from the <strong>Overpass API</strong>, the public query interface for OpenStreetMap. A single bounding-box query retrieves all nodes and ways tagged with <code>amenity</code>, <code>shop</code>, <code>tourism</code>, <code>office</code>, <code>leisure</code>, or <code>healthcare</code> within the Al Karama study area.</p>

    <div class="code">
// Overpass QL query (simplified)
[out:json][timeout:60];
(
  node["amenity"](25.238,55.292,25.259,55.313);
  way["amenity"](25.238,55.292,25.259,55.313);
  node["shop"](25.238,55.292,25.259,55.313);
  // ... + tourism, office, leisure, healthcare
);
out center;
    </div>

    <h4>Processing Pipeline</h4>
    <ol>
        <li><strong>Fetch:</strong> HTTP POST to <code>overpass-api.de</code>; returned 1,419 raw elements</li>
        <li><strong>Parse positions:</strong> Nodes use <code>lat/lon</code> directly; ways use <code>center.lat/center.lon</code> (via <code>out center</code>)</li>
        <li><strong>Filter noise:</strong> Remove "urban furniture" types (bench, waste_basket, parking, shelter, bollard, etc.) &mdash; 18 noise types excluded</li>
        <li><strong>Categorize:</strong> Map ~50 OSM tag values to 8 categories using a lookup table; unmapped <code>shop=*</code> tags default to "shopping"; all others default to "services"</li>
        <li><strong>Label:</strong> Use the <code>name</code> tag if available; otherwise title-case the OSM type (e.g., <code>fast_food</code> &rarr; "Fast Food")</li>
        <li><strong>Cache:</strong> Results saved to <code>pois_cache.json</code> (146 KB); subsequent runs load from cache without an API call</li>
    </ol>

    <div class="finding">
        <strong>Result:</strong> 1,290 PoIs across 8 categories:
        <table>
            <tr><th>Category</th><th>Emoji</th><th>Count</th><th>Example OSM tags</th></tr>
            <tr><td>Shopping</td><td>&#128717;&#65039;</td><td>462</td><td>supermarket, clothes, electronics, jewelry</td></tr>
            <tr><td>Services</td><td>&#127974;</td><td>362</td><td>bank, atm, laundry, hairdresser, police</td></tr>
            <tr><td>Food</td><td>&#127828;</td><td>282</td><td>restaurant, cafe, fast_food, bakery</td></tr>
            <tr><td>Hotel</td><td>&#127976;</td><td>64</td><td>hotel, guest_house, apartment</td></tr>
            <tr><td>Leisure</td><td>&#9917;</td><td>51</td><td>park, sports_centre, cinema, playground</td></tr>
            <tr><td>Health</td><td>&#9877;&#65039;</td><td>48</td><td>pharmacy, clinic, hospital, dentist</td></tr>
            <tr><td>Religious</td><td>&#128332;</td><td>12</td><td>place_of_worship</td></tr>
            <tr><td>Education</td><td>&#127891;</td><td>9</td><td>school, kindergarten, driving_school</td></tr>
        </table>
    </div>

    <h4>Visualisation</h4>
    <p>PoIs are rendered on the 3D map as <strong>emoji icons</strong> using deck.gl's <code>IconLayer</code>. Each category emoji is pre-rendered onto a 64&times;64 HTML canvas and converted to a PNG data URL at page load, which the <code>IconLayer</code> displays as a full-color bitmap texture.</p>

    <ul>
        <li><strong>Collision filtering:</strong> deck.gl's <code>CollisionFilterExtension</code> automatically hides overlapping icons, keeping the display clean at any zoom level</li>
        <li><strong>Text labels:</strong> PoI names appear (via <code>TextLayer</code>) only when zoomed past level 18, also with collision filtering</li>
        <li><strong>Category filter pills:</strong> 8 toggle pills in the control panel let users show/hide individual categories; All/None buttons for bulk control</li>
        <li><strong>Depth-test disabled:</strong> Icons render on top of extruded 3D buildings (<code>parameters: { depthTest: false }</code>)</li>
    </ul>

    <div class="highlight">
        <strong>Design decision &mdash; emoji over colored dots:</strong> Initial implementation used colored circles, but 8 categories produced too many similar colors (e.g., orange food vs amber education; green leisure vs green tree canopy). Emoji icons (&#127828; &#128717;&#65039; &#127976; etc.) are instantly distinguishable without relying on color differentiation.
    </div>

    <h3>9.9 Caveats</h3>
    <div class="limitation">
        <strong>1. Flat terrain assumed:</strong> No elevation model used &mdash; all buildings and trees assumed on same ground plane.
    </div>
    <div class="limitation">
        <strong>2. Trees modeled as solid polygons:</strong> Real tree canopies are porous &mdash; light filters through leaves. Our model treats each canopy polygon as a solid shadow caster, overestimating tree shade somewhat.
    </div>
    <div class="limitation">
        <strong>3. Canopy heights via IDW interpolation:</strong> Only 183 sample points were available for 1,033 polygons. Heights were interpolated using IDW (k=3), introducing spatial smoothing. The 1m resolution of the source raster is reduced.
    </div>
    <div class="limitation">
        <strong>4. Quantized building heights:</strong> GHSL height classes produce discrete height values, leading to quantized shadow lengths.
    </div>
    <div class="limitation">
        <strong>5. No diffusion:</strong> Shadow boundaries are binary (shaded/not shaded) &mdash; no partial shade or penumbra modeled.
    </div>
</div>

<!-- ============================================================ -->
<h2 id="findings">10. Key Findings</h2>
<div class="section">
    <h3>9.1 Correlations</h3>
    <table>
        <tr><th>Relationship</th><th>Correlation (r)</th><th>Interpretation</th></tr>
        <tr><td>GVI ↔ NDVI</td><td><strong>0.501</strong></td><td>Street greenery matches satellite vegetation - data validates!</td></tr>
        <tr><td>SVF ↔ LST</td><td>0.136</td><td>More sky exposure = slightly hotter</td></tr>
        <tr><td>GVI ↔ LST</td><td>-0.039</td><td>More greenery = slightly cooler (weak)</td></tr>
        <tr><td>NDVI ↔ LST</td><td>-0.040</td><td>Vegetation cools surfaces (weak)</td></tr>
    </table>

    <div class="highlight">
        <strong>Why are temperature correlations weak?</strong><br>
        Satellite LST measures <em>surface</em> temperature, but pedestrians experience <em>air</em> temperature and radiant heat. Also, our measurements are at different times (satellite = specific overpass time, street view = whenever image was captured).
    </div>

    <h3>9.2 Main Takeaways</h3>
    <ol>
        <li><strong>Al Karama is hot:</strong> Mean surface temperature of 48.6°C in summer</li>
        <li><strong>Very little vegetation:</strong> Only 3.55% green view, 0.104 NDVI</li>
        <li><strong>Most streets uncomfortable:</strong> 71% have low pedestrian comfort</li>
        <li><strong>Shade helps:</strong> Areas with low SVF are more comfortable</li>
        <li><strong>78% needs intervention:</strong> High or critical priority for heat mitigation</li>
    </ol>
</div>

<!-- ============================================================ -->
<h2 id="limitations">11. Limitations</h2>
<div class="section">
    <div class="limitation">
        <strong>1. Temporal mismatch:</strong> Street view images are from various dates, satellite data is from summer 2024. They don't represent the same moment in time.
    </div>

    <div class="limitation">
        <strong>2. LST ≠ Air temperature:</strong> Satellite measures surface temperature, not what pedestrians feel. Actual thermal comfort depends on air temperature, humidity, wind, and radiant heat.
    </div>

    <div class="limitation">
        <strong>3. Resolution limits:</strong> Satellite data is 10-30m resolution. Fine-scale variations (individual trees, building shadows) are smoothed out.
    </div>

    <div class="limitation">
        <strong>4. Street view sampling bias:</strong> Mapillary images are crowdsourced, so coverage depends on where people drove/walked with cameras. Some areas may have gaps.
    </div>

    <div class="limitation">
        <strong>5. Single season:</strong> We only analyzed summer data. Winter conditions would be different.
    </div>

    <div class="limitation">
        <strong>6. GHSL height classes are coarse:</strong> The GHSL Built-C dataset provides 5 height bands, not precise heights. Buildings are assigned midpoint values (e.g., all 6-15m buildings get 10.5m). This means 94% of buildings share one of only 5 possible height values. GHSL Built-H caps at ~40m, underestimating the tallest buildings in Al Karama.
    </div>
</div>

<!-- ============================================================ -->
<h2 id="files">12. Output Files Reference</h2>
<div class="section">
    <h3>Interactive Viewers</h3>
    <table>
        <tr><th>File</th><th>Description</th></tr>
        <tr><td>index.html</td><td>Main dashboard with links to all visualizations</td></tr>
        <tr><td>viewer.html</td><td>3D Digital Twin &mdash; buildings, shade, thermal, mobility, POIs (deck.gl, 13 layers)</td></tr>
        <tr><td>viewer_2d.html</td><td>2D Analysis Viewer &mdash; centrality, comfort, priority, SVI, satellite, clusters, green access (Leaflet, 7 layers)</td></tr>
        <tr><td>gvi_point_map.html</td><td>GVI point map with clustered markers and image popups</td></tr>
        <tr><td>segmentation_gallery.html</td><td>Sample segmentation images (high vs low vegetation)</td></tr>
    </table>

    <h3>Data Files (<a href="https://github.com/makoto/uob-al-karama/tree/master/docs/data/al_karama" style="color: #1565c0;">data/al_karama/</a>)</h3>
    <table>
        <tr><th>File</th><th>Description</th><th>Records</th></tr>
        <tr><td>area.json</td><td>Area manifest (center, zoom, layer paths, sun info)</td><td>&mdash;</td></tr>
        <tr><td>buildings.geojson</td><td>Building footprints with GEE-enhanced heights</td><td>3,243</td></tr>
        <tr><td>canopy.geojson</td><td>Tree canopy polygons with IDW-interpolated heights</td><td>1,033</td></tr>
        <tr><td>streets.geojson</td><td>Street network with centrality, PCI, LST, priority</td><td>5,656</td></tr>
        <tr><td>pois.json</td><td>Points of interest (8 categories, Overpass API)</td><td>1,290</td></tr>
        <tr><td>combined_svi.json</td><td>Street-level GVI/SVF + satellite LST/NDVI</td><td>10,098</td></tr>
        <tr><td>satellite_grid.json</td><td>Satellite LST/NDVI/NDBI grid (30m, subsampled)</td><td>20,000</td></tr>
        <tr><td>priority_points.json</td><td>Heat mitigation priority scores and levels</td><td>11,576</td></tr>
        <tr><td>segment_comfort.json</td><td>Pedestrian comfort by street segment</td><td>420</td></tr>
        <tr><td>clusters.json</td><td>K-means climate cluster assignments</td><td>10,098</td></tr>
        <tr><td>distance_to_green.json</td><td>Distance to nearest green space</td><td>11,576</td></tr>
        <tr><td>street_shade.csv</td><td>Shade % per street per hour (7 hours)</td><td>5,656</td></tr>
        <tr><td>street_metrics.json</td><td>Street-level aggregated metrics</td><td>5,656</td></tr>
        <tr><td>shadows/shadows_HH.geojson</td><td>Shadow polygons per hour (&times;7 files)</td><td>&mdash;</td></tr>
    </table>

    <h3>Python Scripts</h3>
    <table>
        <tr><th>Script</th><th>Purpose</th></tr>
        <tr><td>setup_gee.py</td><td>Test Google Earth Engine connection</td></tr>
        <tr><td>satellite_analysis.py</td><td>Download and analyze satellite data</td></tr>
        <tr><td>satellite_full_area.py</td><td>Full area grid analysis at 10m</td></tr>
        <tr><td>thermal_sharpening.py</td><td>Downscale LST from 30m to 10m using NDVI regression</td></tr>
        <tr><td>combined_analysis.py</td><td>Merge street-level GVI/SVF with satellite thermal data</td></tr>
        <tr><td>heat_mitigation_priorities.py</td><td>Calculate intervention priorities</td></tr>
        <tr><td>walking_route_analysis.py</td><td>Pedestrian comfort analysis</td></tr>
        <tr><td>network_analysis_v3.py</td><td>Street network centrality</td></tr>
        <tr><td>quick_analyses.py</td><td>Correlations, clusters, accessibility</td></tr>
        <tr><td>gee_building_heights.py</td><td>Extract GHSL/nDSM building heights from GEE, merge with OSM</td></tr>
        <tr><td>shade_analysis.py</td><td>Building + tree canopy shadow projection and street shade coverage analysis</td></tr>
        <tr><td>fetch_canopy_height.py</td><td>Fetch Meta 1m canopy height data from GEE, extract polygons, and assign heights via IDW interpolation</td></tr>
    </table>
</div>

<!-- ============================================================ -->
<h2 id="field-survey">13. Field Survey Guide</h2>
<div class="section">
    <h3>13.1 Objective</h3>
    <p>Validate estimated building heights by conducting on-site measurements using clinometer-based distance-angle methods. A 50m-radius test area was selected around a central Mapillary camera location.</p>

    <h3>13.2 Test Area</h3>
    <table>
        <tr><th>Property</th><th>Value</th></tr>
        <tr><td>Location</td><td>Al Karama, Dubai (25.2421&deg;N, 55.3048&deg;E)</td></tr>
        <tr><td>Radius</td><td>50m</td></tr>
        <tr><td>Camera positions</td><td>8 Mapillary camera locations within the test area</td></tr>
        <tr><td>Center camera ID</td><td>827604215891753</td></tr>
    </table>

    <h3>13.3 Measurement Protocol</h3>
    <p><strong>Buildings to measure:</strong></p>
    <ol>
        <li>Select 3&ndash;5 buildings for calibration</li>
        <li>Vary heights: include low-rise, mid-rise, and high-rise</li>
        <li>Note GPS coordinates for each building</li>
        <li>Take reference photos</li>
    </ol>

    <p><strong>For each building:</strong></p>
    <ul>
        <li>Stand 20&ndash;50m away</li>
        <li>Measure distance to base (GPS or tape measure)</li>
        <li>Measure angle to rooftop (clinometer app)</li>
        <li>Count floors as backup estimate</li>
        <li>Take a photo with a person or car for scale reference</li>
    </ul>

    <div class="formula">
Building Height = Distance &times; tan(Angle) + Observer Height
    </div>

    <h3>13.4 Recommended Apps</h3>
    <table>
        <tr><th>Platform</th><th>Apps</th></tr>
        <tr><td>iOS</td><td>Measure (built-in), Theodolite</td></tr>
        <tr><td>Android</td><td>Smart Measure, Clinometer</td></tr>
        <tr><td>Both</td><td>GPS Coordinates app</td></tr>
    </table>

    <div class="highlight">
        <strong>Tip:</strong> Measure buildings visible from the Mapillary camera positions. The center point (camera 827604215891753) is at 25.242071&deg;N, 55.304779&deg;E. Measurement points at the NE, NW, SE, and SW corners of the 50m radius provide good vantage points for surveying nearby buildings.
    </div>
</div>

<!-- ============================================================ -->
<h2>Tools & Libraries Used</h2>
<div class="section">
    <table>
        <tr><th>Tool</th><th>Purpose</th><th>License</th></tr>
        <tr><td>ZenSVI</td><td>Download Mapillary images, calculate GVI/SVF</td><td>Open source</td></tr>
        <tr><td>Google Earth Engine</td><td>Access satellite imagery</td><td>Free for research</td></tr>
        <tr><td>OSMnx</td><td>Download OpenStreetMap street networks</td><td>MIT</td></tr>
        <tr><td>NetworkX</td><td>Graph/network analysis</td><td>BSD</td></tr>
        <tr><td>scikit-learn</td><td>K-means clustering</td><td>BSD</td></tr>
        <tr><td>GeoPandas</td><td>Geospatial data handling</td><td>BSD</td></tr>
        <tr><td>Leaflet.js</td><td>Interactive web maps</td><td>BSD</td></tr>
        <tr><td>deck.gl</td><td>3D WebGL map visualisation with GPU shadow rendering</td><td>MIT</td></tr>
        <tr><td>SciPy</td><td>Spatial KD-tree for IDW canopy height interpolation</td><td>BSD</td></tr>
    </table>
</div>

<div class="section" style="text-align: center; margin-top: 40px;">
    <p><em>Report generated January 2026</em></p>
    <p><a href="index.html">&larr; Back to Dashboard</a></p>
</div>

<!-- ============================================================ -->
<h2 id="unused-depth">Appendix A: Unused Methodology &mdash; Depth Estimation</h2>
<div class="section">
    <h3>A.1 Concept</h3>
    <p>Monocular depth estimation uses a neural network to predict a per-pixel depth map from a single image. We tested <strong>DepthAnythingV2</strong>, a foundation model that produces a relative depth map where each pixel is assigned a value indicating its distance from the camera (blue = far, red = near).</p>

    <p>The initial hypothesis was that depth maps from street-view images could be used to estimate building heights, supplementing or replacing satellite-derived height data.</p>

    <h3>A.2 What Was Done</h3>
    <p>26 test images from a 50m-radius area (centred on Mapillary camera 827604215891753) were processed as a proof-of-concept. The model successfully produced visually plausible depth maps distinguishing foreground elements (cars, people) from background structures (buildings, sky).</p>

    <h3>A.3 Why It Was Dropped</h3>

    <div class="limitation">
        <strong>Fundamental limitation: relative depth only.</strong> Monocular depth estimation produces <em>relative</em> distances (pixel A is closer than pixel B), not <em>absolute</em> distances in metres. Without camera calibration parameters (focal length, sensor size) &mdash; which Mapillary images do not reliably provide &mdash; there is no way to convert the depth map into real-world measurements.
    </div>

    <p>This means depth estimation cannot answer "this building is 25m tall" &mdash; only "this building is farther away than this car." Building heights require absolute measurements, which this technique cannot provide from the available data.</p>

    <h3>A.4 What Would Make It Viable</h3>
    <table>
        <tr><th>Requirement</th><th>What It Enables</th></tr>
        <tr><td>Stereo image pairs (two images of the same scene from known positions)</td><td>Triangulation for absolute distance</td></tr>
        <tr><td>Camera intrinsics (focal length, sensor size)</td><td>Metric depth from single images</td></tr>
        <tr><td>LiDAR ground truth</td><td>Calibration of relative depth to absolute values</td></tr>
    </table>

    <p>None of these were available from the Mapillary dataset. Adding more single-view images would not resolve the limitation &mdash; the problem is the absence of calibration data, not the quantity of images.</p>

    <h3>A.5 Alternative Used</h3>
    <p>Building heights were instead derived from satellite sources via Google Earth Engine (see <a href="#building-heights">Section 5</a>), achieving 99.5% coverage across 3,243 buildings using GHSL Built-C, GHSL Built-H, nDSM (ALOS&ndash;SRTM), and OSM survey data.</p>
</div>

<!-- ============================================================ -->

<div class="section" style="text-align: center; margin-top: 40px;">
    <p><a href="index.html">&larr; Back to Dashboard</a></p>
</div>

</body>
</html>
